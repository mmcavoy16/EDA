{
    "collab_server" : "",
    "contents" : "---\ntitle: \"EDA:  Introduction and Overview\"\nauthor: \"P. McDonald\"\ndate: \"August 23, 2016\"\ntransition: rotate\nincremental: true\noutput: ioslides_presentation\n---\n\n##What are Data Munging and EDA?\n\n##What are Data Munging and EDA?\n\n*Data Munging* refers to the many tasks required to bring a given data set into a form that facilitates downstream analysis.\n\n##What are Data Munging and EDA?\n\n*Data Munging* refers to the many tasks required to bring a given data set into a form that facilitates downstream analysis.\n\n*Exploratory Data Analysis (EDA)* is a vague term introduced by Tukey which refers to a collection of techniques, often involving visualization, which provide useful summaries of the characteristics of a given data set.\n\n##What are Data Munging and EDA?\n\n*Data Munging* refers to the many tasks required to bring a given data set into a form that facilitates downstream analysis.\n\n*Exploratory Data Analysis (EDA)* is a vague term introduced by Tukey which refers to a collection of techniques, often involving visualization, which provide useful summaries of the characteristics of a given data set.\n\nBy *useful* we mean \"leading to the construction of testable hypotheses, statistical models and a deeper understanding of the data generation phenomena.\"\n\n##What are Data Munging and EDA?\n\n*Data Munging* refers to the many tasks required to bring a given data set into a form that facilitates downstream analysis.\n\n*Exploratory Data Analysis (EDA)* is a vague term introduced by Tukey which refers to a collection of techniques, often involving visualization, which provide useful summaries of the characteristics of a given data set.\n\nBy *useful* we mean \"leading to the construction of testable hypotheses, statistical models and a deeper understanding of the data generation phenomena.\"\n\nFor a few examples, see \n\nhttps://www.stat.berkeley.edu/~brill/Papers/EDASage.pdf\n\n##What is involved in \"doing data science?\"\n\n##What is involved in \"doing data science?\"\n\nAccording to Hadley Wickham, (author of ggplot2 and many other important R packages)\n\n\"First, you get the data in a form that you can work with ... Second, you plot the data to get a feel for what is going on ... Third, you iterate between graphics and models to build a succinct quantitative summary of the data ... Finally, you look back at what you have done, and contemplate what tools you need to do better in the future.\"\n\n##What is involved in \"doing data science?\"\n\nAccording to Hadley Wickham, (author of ggplot2 and many other important R packages)\n\n\"First, you get the data in a form that you can work with ... Second, you plot the data to get a feel for what is going on ... Third, you iterate between graphics and models to build a succinct quantitative summary of the data ... Finally, you look back at what you have done, and contemplate what tools you need to do better in the future.\"\n\nhttp://had.co.nz/thesis/practical-tools-hadley-wickham.pdf\n\n##A word or two from a master\n\nJohn Tukey formalized the notion of exploratory data analysis:\n\nhttp://projecteuclid.org/euclid.aoms/1177704711\n\n##A word or two from a master\n\nJohn Tukey formalized the notion of exploratory data analysis:\n\nhttp://projecteuclid.org/euclid.aoms/1177704711\n\nTukey made many important contributions, among them the FFT, the five number summary, and his view on guiding principles for analyzing data:\n\n\"Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise.\"\n\n##A word concerning context\n\n##A word concerning context\n\nIt is almost always the case that we are working on a project where munging and exploration are but part of a larger goal.\n\n##A word concerning context\n\nIt is almost always the case that we are working on a project where munging and exploration are but part of a larger goal.\n\nThis has important implications for what activities occur during munging and analysis and for this reason it is important to begin each project by consciously addressing \n\n*    what is the problem to be solved and \n*    what the *project workflow* will be.\n\n##A few more words concerning context\n\nThere is a great deal written about how to organize work for a project, and/or workspace:\n\n*    Best practices for software design:  http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\n\n*    How to organize a computational project:  http://www.ncbi.nlm.nih.gov/pubmed/19649301\n\n##A few more words concerning context\n\nThere is a great deal written about how to organize work for a project, and/or workspace:\n\n*    Best practices for software design:  http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\n\n*    How to organize a computational project:  http://www.ncbi.nlm.nih.gov/pubmed/19649301\n\n\"The core guiding principle is simple:  Someone unfamiliar with your project\nshould be able to look at your computer files and understand in detail what you did and why.\"\n\n##A few more words concerning context\n\nThere is a great deal written about how to organize work for a project, and/or workspace:\n\n*    Best practices for software design:  http://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1001745\n\n*    How to organize a computational project:  http://www.ncbi.nlm.nih.gov/pubmed/19649301\n\n\"The core guiding principle is simple:  Someone unfamiliar with your project\nshould be able to look at your computer files and understand in detail what you did and why.\"\n\nRead *PDSwR* Chapter 1.\n\n##What are the prerequisites for getting started?\n\n##What are the prerequisites for getting started?\n\nOverarching requirement:  The ability to systematically organize thought.\n\n##What are the prerequisites for getting started?\n\nOverarching requirement:  The ability to systematically organize thought.\n\nRequired technical tools:\n\n*    Version control:  https://github.com/\n*    Python:  https://www.python.org/\n*    R:  https://www.r-project.org/\n*    R Studio:  https://www.rstudio.com/\n\n##What are the prerequisites?\n\nOverarching requirement:  The ability to systematically organize thought.\n\nRequired technical tools:\n\n*    Version control:  https://github.com/\n*    Python:  https://www.python.org/\n*    R:  https://www.r-project.org/\n*    R Studio:  https://www.rstudio.com/\n\nProjected breakdown for the course:\n\n*    R - 80%\n*    Python - 15%\n*    Linux/Unix - 5%\n\n##R Markdown and reproducible research\n\n##R Markdown and reproducible research\n\nR Markdown is a markup language that supports *reproducible research involving R.*  \n\n##R Markdown and reproducible research\n\nR Markdown is a markup language that supports *reproducible research involving R.*  \n\nReproducible research is the notion that, given the data and the code involved in an analysis, the conclusions of a scientific analysis should be reproducible. \n\n##R Markdown and reproducible research\n\nR Markdown is a markup language that supports *reproducible research involving R.*  \n\nReproducible research is the notion that, given the data and the code involved in an analysis, the conclusions of a scientific analysis should be reproducible. \n\nR Markdown is woven into the R Studio IDE:  http://rmarkdown.rstudio.com/\n\n##R Markdown and reproducible research\n\nR Markdown is a markup language that supports *reproducible research involving R.*  \n\nReproducible research is the notion that, given the data and the code involved in an analysis, the conclusions of a scientific analysis should be reproducible. \n\nR Markdown is woven into the R Studio IDE:  http://rmarkdown.rstudio.com/\n\n\nThe syntax is straightforward:  http://rmarkdown.rstudio.com/authoring_basics.html\n\nThere are analogous tools for python: ipython notebooks.\n\n##How we will partition the semester\n\n*    Workflow and project management (5%)\n*    Structure of R (10%)\n*    Munging (40%)\n*    EDA (40%)\n*    Communication (5%)\n\n##How we will partition the semester\n\n*    Workflow and project management (5%)\n*    Structure of R (10%)\n*    Munging (40%)\n*    EDA (40%)\n*    Communication (5%)\n\nThere will, of course, be a great deal of overlap.  \n\n##How we will partition the semester\n\n*    Workflow and project management (5%)\n*    Structure of R (10%)\n*    Munging (40%)\n*    EDA (40%)\n*    Communication (5%)\n\nThere will, of course, be a great deal of overlap.  \n\nThere will be nonlinearities (recall, Tukey's and Wickham's remarks)\n\n##An overview of munging\n\nBroadly speaking, there are two main tasks associated to munging:\n\n*    Bring the data into a format where it can be analyzed (reshaping)\n*    Assess the quality of the data (validation)\n\n##An overview of munging\n\nBroadly speaking, there are two main tasks associated to munging:\n\n*    Bring the data into a format where it can be analyzed (reshaping)\n*    Assess the quality of the data (validation)\n\nThe first step is almost always the same:  you must read a file.\n\n##An overview of munging\n\nBroadly speaking, there are two main tasks associated to munging:\n\n*    Bring the data into a format where it can be analyzed (reshaping)\n*    Assess the quality of the data (validation)\n\nThe first step is almost always the same:  you must read a file.\n\nFiles come in many different formats (both data structure and information content).  \n\n##An overview of munging\n\nBroadly speaking, there are two main tasks associated to munging:\n\n*    Bring the data into a format where it can be analyzed (reshaping)\n*    Assess the quality of the data (validation)\n\nThe first step is almost always the same:  you must read a file.\n\nFiles come in many different formats (both data structure and information content).  \n\nThe format is completely irrelevant if you don't know how to read any file.\n\n##An overview of munging\n\nBroadly speaking, there are two main tasks associated to munging:\n\n*    Bring the data into a format where it can be analyzed (reshaping)\n*    Assess the quality of the data (validation)\n\nThe first step is almost always the same:  you must read a file.\n\nFiles come in many different formats (both data structure and information content).  \n\nThe format is completely irrelevant if you don't know how to read any file.\n\nOnce you can read a file, it's important that you are able to manipulate what you have read.\n\n##Publically available data\n\nThere is an enormous amount of publically available data out there:\n\nExamples:  http://data.worldbank.org/\n\nhttp://www.census.gov/data.html\n\nhttps://gdc-portal.nci.nih.gov/search/s\n\n##Publically available data\n\nThere is an enormous amount of publically available data out there:\n\nExamples:  http://data.worldbank.org/\n\nhttp://www.census.gov/data.html\n\nhttps://gdc-portal.nci.nih.gov/search/s\n\nhttp://catalog.data.gov/dataset\n\nLet's dive a little deeper into the data.gov site.\n\n##Downloading and opening files\n\nLet's look at the data concerning the cost of electricity:\n\nhttps://catalog.data.gov/dataset/u-s-electric-utility-companies-and-rates-look-up-by-zipcode-feb-2011-57a7c/resource/778eb28b-518a-4a6c-98d4-9b20314e6b77\n\n##Downloading and opening files\n\nLet's look at the data concerning the cost of electricity:\n\nhttps://catalog.data.gov/dataset/u-s-electric-utility-companies-and-rates-look-up-by-zipcode-feb-2011-57a7c/resource/778eb28b-518a-4a6c-98d4-9b20314e6b77\n\nWe can download the csv file by first saving the url and then feeding it to the appropriate R tool:\n\n```{r}\nurl <- \"http://en.openei.org/doe-opendata/dataset/3e440383-a146-49b5-978a-e699334d2e1f/resource/3f00482e-8ea0-4b48-8243-a212b6322e74/download/iouzipcodes2011.csv\"\n```\n\n##Downloading and opening files\n\nNext, download to the appropriate directory:\n\n```{r, eval=FALSE}\ndownload.file(url, \"~/Classes/16-17/Fall/EDA2016/Data/ElecCostCounty.csv\")\n```\n\n##Downloading and opening files\n\nNext, download to the appropriate directory:\n\n```{r, eval=FALSE}\ndownload.file(url, \"~/Classes/16-17/Fall/EDA2016/Data/ElecCostCounty.csv\")\n```\n\nFinally, read the data into R:\n\n/```{r}\ndata1 <- read.csv(\"~/Classes/16-17/Fall/EDA2016/Data/ElecCostCounty.csv\",\n                  header=TRUE)\n/```\n\n##Downloading and opening files\n\nNext, download to the appropriate directory:\n\n/```{r, eval=FALSE}\ndownload.file(url, \"~/Classes/16-17/Fall/EDA2016/Data/ElecCostCounty.csv\")\n/```\n\nFinally, read the data into R:\n\n/```{r}\ndata1 <- read.csv(\"~/Classes/16-17/Fall/EDA2016/Data/ElecCostCounty.csv\",\n                  header=TRUE)\n/```\n\nAlternatively, we can read directly into working memory without downloading:\n\n/```{r,eval =FALSE}\ndata2 <- read.csv(url, header=TRUE)\n/```\n\n##Data provenance\n\nWhenever you download data, you should be sure that you record, at a minimum, the address and time of download.\n\n##Data provenance\n\nWhenever you download data, you should be sure that you record, at a minimum, the address and time of download.\n\nThis is not hard:\n\n/```{r}\nElecCostProvenance <- paste(\"Downloaded from\", url, \"At\", Sys.time(), sep = \" \")\nwrite(ElecCostProvenance, \"~/Classes/16-17/Fall/EDA2016/Data/ElecCostProvenance\")\n/```\n\n##Data provenance\n\nWhenever you download data, you should be sure that you record, at a minimum, the address and time of download.\n\nThis is not hard:\n\n/```{r}\nElecCostProvenance <- paste(\"Downloaded from\", url, \"At\", Sys.time(), sep = \" \")\nwrite(ElecCostProvenance, \"~/Classes/16-17/Fall/EDA2016/Data/ElecCostProvenance\")\n/```\n\nData provenance is becoming a serious issue:\n\nhttp://harvardforest.fas.harvard.edu:8080/exist/apps/datasets/showData.html?id=hf091\n\n##Preliminary R resources\n\nThere are lots of resources to get started:\n\n*    Tutorials for loading data:  https://www.datacamp.com/community/tutorials/r-data-import-tutorial#gs.TeB5CeU\n\n##Preliminary R resources\n\nThere are lots of resources to get started:\n\n*    Tutorials for loading data:  https://www.datacamp.com/community/tutorials/r-data-import-tutorial#gs.TeB5CeU\n*    Books: for example, *The R Cookbook*\n\n##Preliminary R resources\n\nThere are lots of resources to get started:\n\n*    Tutorials for loading data:  https://www.datacamp.com/community/tutorials/r-data-import-tutorial#gs.TeB5CeU\n*    Books: for example, *The R Cookbook*\n*    Stackexchange (google \"read JSON in R\")  http://stackoverflow.com/questions/2061897/parse-json-with-r\n\n##Preliminary R resources\n\nThere are lots of resources to get started:\n\n*    Tutorials for loading data:  https://www.datacamp.com/community/tutorials/r-data-import-tutorial#gs.TeB5CeU\n*    Books: for example, *The R Cookbook*\n*    Stackexchange (google \"read JSON in R\")  http://stackoverflow.com/questions/2061897/parse-json-with-r\n*    Notes  \n\n##A first exercise\n\nOpen R Studio and start a new R Markdown document.\n\n##A first exercise\n\nOpen R Studio and start a new R Markdown document.\n\nGo ahead and knit the document to pdf by clicking the appropriate icon.\n\n##A first exercise\n\nOpen R Studio and start a new R Markdown document.\n\nGo ahead and knit the document to pdf by clicking the appropriate icon.\n\nUse a browser to navigate to the data.gov site.\n\n##A first exercise\n\nOpen R Studio and start a new R Markdown document.\n\nGo ahead and knit the document to pdf by clicking the appropriate icon.\n\nUse a browser to navigate to the data.gov site.\n\nFind the data set involving the city of Somerville, MA. traffic violations.\n\n##A first exercise\n\nOpen R Studio and start a new R Markdown document.\n\nGo ahead and knit the document to pdf by clicking the appropriate icon.\n\nUse a browser to navigate to the data.gov site.\n\nFind the data set involving the city of Somerville, MA. traffic violations.\n\n1.    Read the associated CSV file into memory.\n2.    Read the associated JSON file into memory.\n\n##A first exercise\n\nOpen R Studio and start a new R Markdown document.\n\nGo ahead and knit the document to pdf by clicking the appropriate icon.\n\nUse a browser to navigate to the data.gov site.\n\nFind the data set involving the city of Somerville, MA. traffic violations.\n\n1.    Read the associated CSV file into memory.\n2.    Read the associated JSON file into memory.\n\nProvide code chunks in the R Markdown document that accomplishes the above tasks.\n\n\n\n\n\n",
    "created" : 1472135618835.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2681891327",
    "id" : "D2028D5D",
    "lastKnownWriteTime" : 1472142170,
    "last_content_update" : 1472142170058,
    "path" : "C:/Users/homur/OneDrive/New College/EDA/Week 1/Lecture-1.Rmd",
    "project_path" : "Lecture-1.Rmd",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}